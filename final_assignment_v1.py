# -*- coding: utf-8 -*-
"""Final_Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QAWO_vweN4jENkr9FUIQyGixUoLU_6nx
"""

import cv2
def export_video (frames):
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # video codec
    fps = 30  # fps
    width, height = frames[0].shape[0], frames[0].shape[1]  # Set the video dimensions
    # Set where the new frames will go to
    video_output = cv2.VideoWriter('output.mp4', fourcc, fps, (width, height))

    # Write each frame into the video
    for frame in frames:
        video_output.write(frame)

import cv2

def get_input_video (video_name):
    # Import the video as a list of frames
    vid = cv2.VideoCapture(video_name)

    return vid

import cv2

def face_detection (input_video):
    # Get the video
    vid = get_input_video(input_video)

    # Create a CascadeClassifier, an object for face detection using Haar 
    # feature-based cascade classifiers as proposed by Paul Viola and Michael Jones
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

    # Create a MultiTracker object to help track each face
    multi_tracker = cv2.MultiTracker_create()

    # A list of frames that will later be compiled into a video
    list_of_frames = list()

    # Get the first frame of the video
    # This first time is outside the loop to emulate a "do{} while()" loop
    frame_exists, frame = vid.read()

    # Loop through each frame in the video
    while frame_exists:

        # Convert each frame to grayscale
        grayscale_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Detect faces in the frame using the previosly defined CascadeClassifier
        # Note: Faces are detected in grayscale, but the ractagle is drawn over
        # the coloured frame
        faces = face_cascade.detectMultiScale(grayscale_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

        # Update the MultiTracker object with the current frame
        for face in faces:
            (x, y, z, p) = face
            multi_tracker.add(cv2.TrackerKCF_create(), frame, (x, y, z, p))

        # Update the MultiTracker object
        success, boxes = multi_tracker.update(frame)

        # Draw rectangles around the tracked faces
        for i, new_box in enumerate(boxes):
            # Get coordinates for the rectangle
            x, y, w, h = new_box[:4]
            corner1 = (int(x), int(y))
            corner2 = (int(x + w), int(y + h))
            # Draw a rectangle around the list
            cv2.rectangle(frame, corner1, corner2, (0, 255, 0), 2)

        # Add the frame to the list
        list_of_frames.append(frame)

        # Get the following frame for the next loop iteration
        end_of_video, frame = vid.read()